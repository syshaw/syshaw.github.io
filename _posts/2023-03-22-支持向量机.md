---
title: 十大经典算法之一：支持向量机(SVM)
categories: [机器学习]
comments: true
---
## 定义
支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。

关键字：间隔最大、SVM依赖样本距离

SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面：就是要找到各类样本点到超平面的距离最远；



SVM的主要思想是将数据集映射到高维空间，通过在空间中找到最优间隔来确定分类边界。
SVM尝试着找到最大间隔超平面，该分割超平面可以将数据集分成两个相互独立的部分。	

## 最大间隔超平面
两类样本分别分割在该超平面的两侧；
两侧距离超平面最近的样本点到超平面的距离被最大化了。

## 支持向量



一些与chatGPT的Q&A:

> 1、如果数据集映射到高维空间后，存在一定量的交集，这时候SVM的超平面应该怎么找，用什么方法处理？
```
如果将数据集映射到高维空间后存在交集，这时超平面可能无法完全分隔两个类别之间的数据，也就是说，数据可分性不好。这时候就需要使用一些特殊的技巧来处理这种情况。下面是两种比较常见的方法：

核方法：SVM可以使用核方法来将低维空间中不可分的数据映射到高维空间中。通过选择合适的核函数，SVM可以把所有不能被超平面完全分割的数据变成线性可分的，进而可以使用线性划分算法进行分类或回归。常见的核函数包括线性核、多项式核、径向基函数（RBF）核等。

松弛变量：SVM给了我们调整数据分类的权力。我们可以通过引入一些松弛变量让数据有一定程度的错误，即加入一部分误差来处理交集。通过适当的权衡超平面的间隔和松弛变量，可以使得SVM在一定程度上容忍错误，并得到更好的分类效果。

这些技巧可以帮助SVM更好地处理无法完全线性分离的数据集，从而提高分类的准确性和性能。
```

参考：
> https://zhuanlan.zhihu.com/p/77750026