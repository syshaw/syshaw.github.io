---
title: 딥러닝/머신러닝 연구의 미래
categories: [CS]
comments: true
---

### #1 Sridhar Mahadevan의 invited talk at Standford Univ. 요약[^1] <br>(2017년 12월)

오늘날의 머신러닝 연구는 대부분 이제 학계에서가 아니라 산업체<sup>industry</sup>에서 이루어집니다. 보다 기초적인 이론을 자율주행 자동차와 같은 난제<sup>challenging problems</sup>에 적용시키는 것으로 바뀌었죠. 

빌 게이츠는 뉴욕 타임즈와의 인터뷰에서 "기계가 스스로 학습할 수 있도록하는 획기적인 변혁<sup>breakthrough</sup>을 만들어낸다면, 그 가치는 마이크로소프트의 10배일 것이다"라고 말했습니다. 그의 말이 맞다면 머신러닝의 잠재적 시장가치는 약 5조 달러 정도 되겠지요. 

이 경우, 학계에 있던 머신러닝 인재들이 산업계로 넘어간 사실이 놀랍지 않습니다. 훨씬 더 많은 데이터와 흥미로운 난제들이 가득하니까요. 따라서 학계'만'의 머신러닝은 점차 줄고 있으며, 그 추세는 바뀌지 않을 것으로 보입니다.

어떠한 분야에서 연구의 영향력은 <dfn info="투입량 대비 생산(결과)의 증가량이 줄어드는 현상">수확체감의 법칙</dfn><sup>diminishing returns</sup>을 따릅니다. 

무슨 말인지 예를 들면, Havard의 유명한 정치학자 Gary King은 문서를 체계적으로 군집화<sup>clustering</sup>하는 방법에 대해 조사를 한 적이 있습니다. 그의 노예인 박사과정 학생은 모든 문헌을 뒤져서 총 250개의 알고리즘을 찾아냈습니다. 자 여기서, 누군가 251번째의 새로운 알고리즘을 발명하는게 얼마나 가치가 있을까요? 

머신러닝에도 똑같은 이야기가 적용됩니다. GAN이든 강화학습이든 각 분야에서 수백개가 넘는 새로운 '방법'들이 논문화되었죠. 그중 대부분은 맨 처음의 원본 논문 이상으로 깊게 논의되지 않습니다. 그럼에도 새로운 방법을 이용한 새로운 논문들은 지금 이 순간에도 계속 나오고 있습니다

궁극적으로, 연구의 영향력이란 어떠한 새로운 분야에서 '선도자'가 될 때 최대가 됩니다. 그 분야에서 가장 처음으로 영향력 있는 논문을 쓴 사람은 연구적 명성의 대부분을 얻게 됩니다. 

1984년 Leslie Valiant는 PAC Learning이란 분야를 개척한 "A Theory of the Learnable"라는 논문을 썼습니다. 현재 Google Scholar 인용 수는 6천개가 넘고, 그후 수천개의 논문이 이 모델을 발전시켜서 쓰여졌습니다. 

하지만 CS분야 최고 영예의 상인 Turing Award는 분야를 개척한 공로로 인해 Leslie Valiant에게 돌아갔죠. 즉, 누군가의 모델을 응용한 n번째 저자가 되는게 아니라 새로운 분야를 개척하는 것이 이상적입니다.

요즘 머신러닝 학회에는 6천명이 넘는 사람들이 참석합니다. 남들이 안하는 거 하는 50여명이 참석했던 1985년의 학회 때와는 크게 달라졌죠. 이러한 분야에서 응용분야가 아니라 새로운 기초를 제시하는 것<sup>make a basic contribution</sup>은 매우 어렵습니다. 불가능하진 않지만 매우 어렵습니다. 도전해볼만 할 가치가 있는지 결정하는 것은 여러분의 몫입니다.

---


### #2 MIT Technology Review 요약[^2] (2019년 1월)


오늘날 사람들이 들어봤을 AI<sup>인공지능</sup>분야의 성과는 대부분이 딥러닝 덕분이다. 딥러닝은 통계학을 이용해 데이터의 패턴을 찾아서, 거의 인간 만큼이나 잘 '보고' '듣게' 만든다. 

심지어 좁은 분야이지만 인간처럼 논리적인 근거에 따라 판단도 할 수 있다. 현재 구글 검색, 페이스북의 피드, 넷플릭스의 추천엔진 등에 사용되며, 헬스케어와 교육과 같은 분야도 큰 변화를 목전에 두고 있다.

비록 딥러닝이 대중에겐 AI의 중심으로 보일지라도, 사실 오랜 인공지능 연구의 역사에선 하나의 작은 변화일 뿐이다. 딥러닝이 해당 분야의 선두가 된 것은 아직 10년도 되지 않았다. 역사가 주는 교훈으로 판단한다면 곧 딥러닝 또한 다른 무언가에게 선두를 내줄 가능성이 높다.

오랫동안 AI 분야에선 다양한 신기술이 등장했다가 지는 것을 반복해왔다. 우리는 arXiv의 'artificial intelligence' 섹션에서 2018년 11월 18일 전까지의 16,625개 논문의 초록을 다운받은 후, 사용되는 단어에 대한 분석을 수행하였다. 

최근 25년간 사용된 대부분의 기술들은 거의 비슷한 시기인 1950년대에 등장했다. 그후 성장과 추락을 반복해왔다. 예를 들어 neural network는 60년대에 피크를 쳤고 80년대에도 짧게 반짝 했다가 거의 사장되었지만, 최근 deep learning 때문에 엄청난 인기를 얻었다.

매 10년마다 뭔가 다른 기술이 대세를 차지한다. 50년대 후반과 60년대는 neural network, 70년대는 various symbolic approach, 80년대는 knowledge-based system, 90년대는 Bayesian network, 2000년대는 support vector machine, 그리고 2010년대엔 다시 neural network이다.

2020년대에는 어떨까? 크게 다르지 않을 것으로 예상한다. 그렇다면 딥러닝의 시대는 거의 저물고 있다는 뜻이다. 수많은 이들이 다음 대세를 위해 아이디어를 연구하고 있다. 오래된 기술들이 다시 대세가 될 수도 있고, 아예 새로운 패러다임이 등장할 수도 있다.

---


### #3 Q. 딥러닝의 시대는 언제 끝날까요? [^3] (2019년 9월)

전 MIT 교수인 Thomas Kuhn은 "과학이란 진리<sup>truth</sup>의 절대적인 척도에 따라 나아가는 것이 아니라, 종사자들이 암묵적으로 동의한 '변형된 패러다임'안에서 나아갈 뿐"이라는 말을 남겼습니다. 

딥러닝 또한 "가장 중요한 것은 dataset에서 error를 최소화하는 성능이며, 그 결과를 설명하는 것<sup>explainability</sup>은 전혀 중요하지 않다" 라는 맹신이 절대적으로 필요한 '패러다임'일 뿐입니다. 

이러한 '교리<sup>tenet</sup>'가 꼭 필요하지도 충분하지도 않으며, 오히려 과학으로서 AI의 발전을 저해하고 있다는 것을 AI 연구자들이 깨달았을 때, 딥러닝의 시대는 끝날 것입니다. 

지난 수년간 딥러닝을 유명하게 한 ImageNet dataset을 예로 듭시다. 만약 어떤 newtwork이 ImageNet에서 error를 적게 냈다면, 비록 수천개의 layer로 이루어져 거의 이해하기 어려울지라도, 이를 computer vision 분야의 '진보<sup>forward progress</sup>'라 여겨왔습니다.

좀 오래되었지만 이 분야의 '진보'에 대한 그래프입니다.

![]({{ "/assets/img/post/d.png" | absolute_url }})

와우! 성능이 사람보다 훨씬 좋아졌네요. 만약 이 결과를 보고 우리가 human vision을 이해하는 데에 어느정도 성과를 냈다고 느꼈거나, 심지어 실제로 computer vision이 human vision보다 낫다고 생각을 했다면 당신은 '딥러닝교'에 빠져버린 것입니다.

우리 인간이 '인지<sup>perceive</sup>'하는 능력이 과연 ImageNet같은 몇몇 dataset을 이용해 점수화될 수 있을까요? 이 딥러닝 네트워크를 구성하는 수십억개의 변수들이 진짜로 무슨 의미인지 우리가 알 수 있을까요?

누구나 간단히 이 ImageNet을 이용한 딥러닝 네트워크를 다운받아 테스트해볼 수도 있습니다. MATLAB을 키고, 노트북의 캠을 킨 다음 집안을 돌아다녀보는 것이죠. 조금만 해봐도 얼마나 성능이 끔찍한지 알 수 있을 거예요. 2살짜리 아이보다도, 심지어 우리 강아지보다도 못합니다. 

Johns Hopkins의 Yuille 교수는 "Deep Nets는 benchmarked dataset에선 잘 작동하지만, dataset 밖 실제 이미지에는 처참히 실패한다. 또한 사람과 달리 이미지의 작은 변화에도 너무 민감하다."라고 말했습니다.

딥러닝 지지자는 'ImageNet의 data가 충분하지 않아서 그렇다, 수십억 혹은 수십조개의 이미지를 학습시키다보면 언젠가는 좋아지지 않을까'라고 생각할 수도 있습니다. 하지만 아무리 많은 데이터라도 실제 세상의 복잡성<sup>complexity</sup>을 나타내긴 어렵습니다.

즉 딥러닝을 가로지르는 '패러다임'이란 '실제 세상에서 사람의 능력(인지, 언어, 행동 등)을 구현하는 것은 마치 <dfn info="함수에서 input과 output 사이에 있는">black box</dfn>를 만드는 것과 같다'라는 가정에 기반합니다.

물론 이러한 black box를 만들면 구체적이고 셀 수 있는 '수치'를 만들 수 있으며, 성능 '진보'에 대한 그래프를 그릴 수 있겠지요. 노벨상 수상자인 Robert Coase는 "과학 이론은 버스 시간표와 다르다, 비록 예측률이 떨어지더라도 더 깊은 insight을 주는 이론이 성공적인 이론이다'라고 말했습니다. 




---


<br><br><br>

[^1]: [https://qr.ae/TWIb2C](https://qr.ae/TWIb2C)
[^2]: [https://www.technologyreview.com/s/612768/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/](https://www.technologyreview.com/s/612768/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/)
[^3]: [https://qr.ae/TxOgGD](https://qr.ae/TxOgGD)

